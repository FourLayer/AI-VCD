{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPk0Ftq4S8+LMeFCMb6sMEt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["제3자의 예측 테스트"],"metadata":{"id":"liyQGPU4vaWH"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BXsPsUakdkHL","executionInfo":{"status":"ok","timestamp":1701856262792,"user_tz":-540,"elapsed":2625,"user":{"displayName":"네겹살","userId":"07379518830981247350"}},"outputId":"99c88a5c-9628-48e5-b032-dd650b3675cc"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# 모델 로드\n","\n","from keras.models import load_model\n","model = load_model('/content/drive/MyDrive/코드/model_fin.h5')"],"metadata":{"id":"JcRH56CByI8e","executionInfo":{"status":"ok","timestamp":1701856277418,"user_tz":-540,"elapsed":497,"user":{"displayName":"네겹살","userId":"07379518830981247350"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6kstQaavZSz","executionInfo":{"status":"ok","timestamp":1701856315754,"user_tz":-540,"elapsed":14841,"user":{"displayName":"네겹살","userId":"07379518830981247350"}},"outputId":"e1482224-0a17-4c99-9cc8-7546dfe4a5db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter the folder path: /content/drive/MyDrive/음성데이터셋/새나/human/week6\n","1/1 [==============================] - 0s 36ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=816\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=840\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=952\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 22ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=584\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=728\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 28ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=776\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 35ms/step\n","File: /content/drive/MyDrive/음성데이터셋/새나/human/week6/2.wav, Predicted class: Human\n","File: /content/drive/MyDrive/음성데이터셋/새나/human/week6/5.wav, Predicted class: Human\n","File: /content/drive/MyDrive/음성데이터셋/새나/human/week6/3.wav, Predicted class: Human\n","File: /content/drive/MyDrive/음성데이터셋/새나/human/week6/1.wav, Predicted class: AI\n","File: /content/drive/MyDrive/음성데이터셋/새나/human/week6/6.wav, Predicted class: Human\n","File: /content/drive/MyDrive/음성데이터셋/새나/human/week6/4.wav, Predicted class: AI\n","File: /content/drive/MyDrive/음성데이터셋/새나/human/week6/8.wav, Predicted class: Human\n","File: /content/drive/MyDrive/음성데이터셋/새나/human/week6/10.wav, Predicted class: Human\n","File: /content/drive/MyDrive/음성데이터셋/새나/human/week6/9.wav, Predicted class: Human\n","File: /content/drive/MyDrive/음성데이터셋/새나/human/week6/7.wav, Predicted class: Human\n"]}],"source":["import os\n","\n","def predict_audio_files(model):\n","    # 사용자로부터 폴더 경로 입력 받기\n","    folder_path = input(\"Please enter the folder path: \")\n","\n","    results = []\n","    # 폴더 안의 모든 파일에 대해\n","    for filename in os.listdir(folder_path):\n","        # 파일이 .wav로 끝나는 경우에만 처리\n","        if filename.endswith(\".wav\"):\n","            audio_file = os.path.join(folder_path, filename)\n","            features = []\n","\n","            try:\n","                y, sr = librosa.load(audio_file)\n","\n","                # 원본 데이터에 대한 특성 추출\n","                mfccs = librosa.feature.mfcc(y=y, sr=sr)\n","                chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)\n","                tonnetz = librosa.feature.tonnetz(y=y, sr=sr)\n","\n","                original_features = np.concatenate((np.mean(mfccs, axis=1), np.mean(chroma_cqt, axis=1), np.mean(tonnetz, axis=1)))\n","\n","                features.append(original_features)\n","\n","            except Exception as e:\n","                print(f\"Error processing {audio_file}: {str(e)}\")\n","\n","            # 데이터 차원 재조정 (Conv1D 레이어는 3차원 입력을 기대합니다)\n","            features = np.expand_dims(features, axis=2)\n","\n","            # 모델로부터 예측 결과 얻기\n","            prediction = model.predict(features)\n","\n","            # 가장 확률이 높은 클래스 결정 및 저장\n","            predicted_class = 'AI' if prediction[0][0] < 0.5 else 'Human'\n","            results.append((audio_file, predicted_class))\n","\n","    return results\n","\n","# 폴더 안의 모든 .wav 파일에 대한 예측 수행\n","predictions = predict_audio_files(model)\n","\n","# 예측 결과 출력\n","for audio_file, predicted_class in predictions:\n","    print(f\"File: {audio_file}, Predicted class: {predicted_class}\")"]}]}