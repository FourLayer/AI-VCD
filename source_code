import os
import librosa
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

def extract_silence_features(audio_path, sr):
    # 음성 데이터 로드
    audio, _ = librosa.load(audio_path, sr=sr)  # 샘플링 레이트를 sr로 설정

    # 숨소리로 예상되는 부분 추출
    intervals = librosa.effects.split(audio, top_db=20)
    silence_features = []
    for interval in intervals:
        start, end = interval
        silence_segment = audio[start:end]
        feature = extract_feature(silence_segment, sr)  # 샘플링 레이트를 sr로 설정하여 특성 추출 함수 호출
        silence_features.append(feature)

    return silence_features

def extract_feature(audio, sr):
    # 숨소리의 특성 추출 (멜 스펙트로그램)
    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr)  # 멜 스펙트로그램 특성 추출
    log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)  # 로그 스케일 변환
    return log_mel_spec

# sena2/ai와 sena2/human의 음성 파일 경로
ai_path = '/content/drive/MyDrive/PBL/sena2/ai'
human_path = '/content/drive/MyDrive/PBL/sena2/human'

# AI 음성 파일에서 숨소리로 예상되는 부분 추출
ai_silence_features = []
ai_files = os.listdir(ai_path)
for file in ai_files:
    if file.endswith('.wav'):
        file_path = os.path.join(ai_path, file)
        silence_features = extract_silence_features(file_path, 16000)  # 샘플링 레이트를 16000으로 설정하여 호출
        ai_silence_features.extend(silence_features)

# Human 음성 파일에서 숨소리로 예상되는 부분 추출
human_silence_features = []
human_files = os.listdir(human_path)
for file in human_files:
    if file.endswith('.wav'):
        file_path = os.path.join(human_path, file)
        silence_features = extract_silence_features(file_path, 16000)  # 샘플링 레이트를 16000으로 설정하여 호출
        human_silence_features.extend(silence_features)

# AI와 Human 숨소리 특성을 동일한 크기로 맞추기
max_length = max(max(feature.shape[1] for feature in ai_silence_features), max(feature.shape[1] for feature in human_silence_features))
ai_silence_features = [np.pad(feature, ((0, 0), (0, max_length - feature.shape[1])) , mode='constant') for feature in ai_silence_features]
human_silence_features = [np.pad(feature, ((0, 0), (0, max_length - feature.shape[1])) , mode='constant') for feature in human_silence_features]

# AI와 Human 숨소리 특성을 합친 데이터셋 생성
X = np.array(ai_silence_features + human_silence_features)
y = np.concatenate((np.zeros(len(ai_silence_features)), np.ones(len(human_silence_features))), axis=0)

# 데이터셋을 학습용과 테스트용으로 나누기
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 데이터셋 reshape
n_samples, n_mels, n_frames = X_train.shape
X_train = X_train.reshape(-1, n_mels * n_frames)
X_test = X_test.reshape(-1, n_mels * n_frames)

# SVM 모델 학습 및 예측
svm_model = SVC(kernel='linear', probability=True)  # probability=True로 설정하여 예측 확률을 얻을 수 있도록 설정
svm_model.fit(X_train, y_train)
y_pred = svm_model.predict(X_test)
y_pred_proba = svm_model.predict_proba(X_test)  # 예측 확률 계산


# AI를 AI로 예측할 평균 확률과 Human을 Human이라고 예측할 평균 확률 계산
ai_ai_proba = np.mean(y_pred_proba[y_test == 0][:, 0])  # AI를 AI로 예측할 확률의 평균
human_human_proba = np.mean(y_pred_proba[y_test == 1][:, 1])  # Human을 Human이라고 예측할 확률의 평균

print("AI를 AI로 예측할 평균 확률:", ai_ai_proba)
print("Human을 Human이라고 예측할 평균 확률:", human_human_proba)
