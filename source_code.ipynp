import os
import librosa
import numpy as np
from sklearn.svm import OneClassSVM
from sklearn.model_selection import GridSearchCV

def extract_silence_features(audio_path, sr):
    # 음성 데이터 로드
    audio, _ = librosa.load(audio_path, sr=sr)

    # 숨소리로 예상되는 부분 추출
    intervals = librosa.effects.split(audio, top_db=20)
    silence_features = []
    for interval in intervals:
        start, end = interval
        silence_segment = audio[start:end]
        feature = extract_feature(silence_segment, sr)
        silence_features.append(feature)

    return silence_features

def extract_feature(audio, sr):
    # 숨소리의 특성 추출 (멜 스펙트로그램)
    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr)
    log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)
    return log_mel_spec

# 학습용 Human 음성 파일에서 숨소리로 예상되는 부분 추출
human_train_path = '/content/drive/MyDrive/음성데이터셋/sena4/train/human'
human_train_files = os.listdir(human_train_path)
human_train_silence_features = []
for file in human_train_files:
    if file.endswith('.wav'):
        file_path = os.path.join(human_train_path, file)
        silence_features = extract_silence_features(file_path, 16000)
        human_train_silence_features.extend(silence_features)

# 테스트용 Human 음성 파일에서 숨소리로 예상되는 부분 추출
human_test_path = '/content/drive/MyDrive/음성데이터셋/sena4/test/human'
human_test_files = os.listdir(human_test_path)
human_test_silence_features = []
for file in human_test_files:
    if file.endswith('.wav'):
        file_path = os.path.join(human_test_path, file)
        silence_features = extract_silence_features(file_path, 16000)
        human_test_silence_features.extend(silence_features)

# AI 음성 파일에서 숨소리로 예상되는 부분 추출
ai_path = '/content/drive/MyDrive/음성데이터셋/sena4/test/ai'
ai_files = os.listdir(ai_path)
ai_silence_features = []
for file in ai_files:
    if file.endswith('.wav'):
        file_path = os.path.join(ai_path, file)
        silence_features = extract_silence_features(file_path, 16000)
        ai_silence_features.extend(silence_features)

# AI와 Human 숨소리 특성을 동일한 크기로 맞추기
def pad_features(features, max_length):
    return [np.pad(feature, ((0, 0), (0, max_length - feature.shape[1])) , mode='constant') for feature in features]

max_length = max(max(feature.shape[1] for feature in human_train_silence_features), 
                 max(feature.shape[1] for feature in human_test_silence_features), 
                 max(feature.shape[1] for feature in ai_silence_features))

human_train_silence_features = pad_features(human_train_silence_features, max_length)
human_test_silence_features = pad_features(human_test_silence_features, max_length)
ai_silence_features = pad_features(ai_silence_features, max_length)

# 학습용 데이터 생성
X_train = np.array(human_train_silence_features)
y_train = np.ones(len(X_train))

# 테스트용 데이터 생성
X_test = np.array(human_test_silence_features + ai_silence_features)
y_test = np.concatenate((np.ones(len(human_test_silence_features)), np.zeros(len(ai_silence_features))))

# 데이터셋 reshape
n_samples_train, n_mels, n_frames_train = X_train.shape
X_train = X_train.reshape(-1, n_mels * n_frames_train)

n_samples_test, _, n_frames_test = X_test.shape
X_test = X_test.reshape(-1, n_mels * n_frames_test)

# One-class SVM 모델 학습
one_class_svm_model = OneClassSVM()

# 하이퍼파라미터 그리드 설정
param_grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 
              'nu': [0.01, 0.1, 0.2, 0.5]}

# GridSearchCV 초기화
grid_search = GridSearchCV(one_class_svm_model, param_grid, cv=5, scoring='accuracy')

# GridSearchCV 학습
grid_search.fit(X_train, y_train)

# 최적의 하이퍼파라미터 출력
print('Best parameters:', grid_search.best_params_)

# 최적의 하이퍼파라미터로 학습된 모델 추출
best_model = grid_search.best_estimator_

# 테스트 데이터에 대한 예측
y_pred = best_model.predict(X_test)

# 예측 결과를 binary로 변환
y_pred_binary = np.where(y_pred == -1, 0, 1)

# AI를 AI로 예측할 평균 확률 및 Human을 Human이라고 예측할 평균 확률 계산
ai_ai_proba = np.mean(y_pred_binary[y_test == 0])
human_human_proba = np.mean(y_pred_binary[y_test == 1])

print("AI를 AI로 예측할 평균 확률:", ai_ai_proba)
print("Human을 Human이라고 예측할 평균 확률:", human_human_proba)
